{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# 请到 https://platform.deepseek.com/api_keys 申请api填入下方，新用户赠送10元额度的token完全支持本次baseline速通~\n",
    "DEEPSEEK_API_KEY = 'sk-8c785b34312444a38f0f62b7aceb5c30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取参考数据集\n",
    "import json,time\n",
    "from functools import reduce\n",
    "novel_data = []\n",
    "with open('./参考数据集.json', 'r',encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        novel_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看数据集中第 1 本小说的名字\n",
    "novel_data[5]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_data[0].keys(), len(novel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看数据集中所有小说的名字和字数\n",
    "for i in novel_data:\n",
    "    print(f\"《{i['name']}》的字数为： {len(i['text'])} 字\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集中第 4 本小说《呼啸山庄》的文本作为训练集数据来源\n",
    "data = novel_data[3][\"text\"]\n",
    "story_name = novel_data[3][\"name\"]\n",
    "# 查看《呼啸山庄》全文\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装必要的库\n",
    "!pip install jieba loguru openai -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分《呼啸山庄》的文本为 800 字一段的段落\n",
    "import jieba\n",
    "\n",
    "paragraphs = []\n",
    "for i in range(len(novel_data)):\n",
    "    # 读取数据集中第 4 本小说《呼啸山庄》的文本作为训练集数据来源\n",
    "    data = novel_data[i][\"text\"]\n",
    "    story_name = novel_data[i][\"name\"]\n",
    "    # 利用jieba进行句子切分\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in data.split('。'):  # 使用句号作为切分符\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    # 将句子合并成800字一段的段落\n",
    "    current_paragraph = ''\n",
    "    for sentence in sentences:\n",
    "        if len(current_paragraph) + len(sentence) <= 800:\n",
    "            current_paragraph += sentence+'。'\n",
    "        else:\n",
    "            paragraphs.append(current_paragraph.strip())\n",
    "            current_paragraph = sentence\n",
    "\n",
    "    # 将最后一段加入到段落列表中\n",
    "    if current_paragraph:\n",
    "        paragraphs.append(current_paragraph.strip())\n",
    "\n",
    "    # 打印切分后的段落\n",
    "    for idx, paragraph in enumerate(paragraphs):\n",
    "        print(f'段落 {idx + 1}: {paragraph}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "from openai import OpenAI\n",
    "# 配置loguru输出到文件\n",
    "logger.remove()  # 移除默认的控制台输出\n",
    "logger.add(\"logs/app_{time:YYYY-MM-DD}.log\", level=\"INFO\", rotation=\"00:00\", retention=\"10 days\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用deepseek-chat api给段落打标签的接口\n",
    "def get_response(text):\n",
    "    client = OpenAI(\n",
    "        api_key=DEEPSEEK_API_KEY,  # 如果您没有配置环境变量，请在此处用您的API Key进行替换\n",
    "        base_url=\"https://api.deepseek.com\",  # 填写DashScope SDK的base_url\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'system', \n",
    "                'content': '总结user提交的内容。用一句不超过50字的话总结这段小说的情节。仅回答总结，不需要添加其他内容。'\n",
    "            },\n",
    "            {\n",
    "                'role': 'user', \n",
    "                'content': text\n",
    "            }\n",
    "        ])\n",
    "    \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置容错机制，可最多重试 5 次，如果失败记录错误日志\n",
    "def get_summary_with_retry(text):\n",
    "    max_retries = 5\n",
    "    retry_delay = 5  # in seconds\n",
    "    attempts = 0\n",
    "    while attempts < max_retries:\n",
    "        try:\n",
    "            return get_response(text)\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            if attempts < max_retries:\n",
    "                logger.warning(f\"Attempt {attempts} failed for text: {text}. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                logger.error(f\"All {max_retries} attempts failed for text: {text}. Error: {e}\")\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建文件夹\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "os.makedirs('dataset', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量给指定的小说打标签的接口函数\n",
    "def build_dataset(novel,texts):\n",
    "    instruction_prompt = \"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\"\n",
    "    dataset = []\n",
    "    dataset_error = []\n",
    "    for text in tqdm(texts, desc=f\"Processing {novel}\", total=len(texts)):\n",
    "        try:\n",
    "            summary = get_summary_with_retry(text)\n",
    "            # print(summary)\n",
    "            dataset.append({\n",
    "                \"instruction\": instruction_prompt,\n",
    "                \"input\": summary,\n",
    "                \"output\": text\n",
    "            })\n",
    "        except Exception as e:\n",
    "            dataset_error.append(text)\n",
    "            logger.error(f\"Failed to process text: {text}. Error: {e}\")\n",
    "    \n",
    "    with open(f\"./data/{novel}.json\", \"w\") as f:\n",
    "        f.write(json.dumps(dataset, ensure_ascii=False, indent=4))\n",
    "\n",
    "    with open(f\"./data/{novel}_error.txt\", \"w\") as f:\n",
    "        f.write(json.dumps(dataset_error, ensure_ascii=False, indent=4))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始给《呼啸山庄》前30%的段落打标签\n",
    "dataset = build_dataset(story_name,paragraphs[:len(paragraphs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "# 更换 pypi 源加速库的安装\n",
    "!pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 安装微调所需要的库\n",
    "!pip install -U huggingface_hub modelscope  \"transformers>=4.37.0\" streamlit==1.24.0 sentencepiece==0.1.99 accelerate==0.27.2 transformers_stream_generator==0.0.4 datasets==2.18.0 peft==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载模型\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "# 第一次下载时打开\n",
    "model_dir = snapshot_download('Qwen/Qwen2-1.5B-Instruct',cache_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 设置文件夹路径\n",
    "directory_path = './data'\n",
    "\n",
    "# 初始化一个空列表，用于存储合并后的数据\n",
    "merged_data = []\n",
    "\n",
    "# 遍历文件夹下的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    # 检查文件扩展名是否为.json\n",
    "    if filename.endswith('.json'):\n",
    "        # 构建文件的完整路径\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        # 打开并读取JSON文件\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            # 加载JSON内容到变量\n",
    "            data = json.load(file)\n",
    "            # 将当前文件的数据添加到合并列表中\n",
    "            merged_data.extend(data)\n",
    "\n",
    "# 将合并后的数据转换为JSON格式\n",
    "merged_json = json.dumps(merged_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 可以选择将合并后的数据写入到一个新的JSON文件中\n",
    "output_file_path = './dataset/merged_story.json'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(merged_json)\n",
    "\n",
    "# 或者直接输出到控制台\n",
    "print(merged_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将JSON文件转换为CSV文件\n",
    "df = pd.read_json('./dataset/merged_story.json')\n",
    "# df = pd.read_json('./data/story/呼啸山庄.json')\n",
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds[:3])  # 查看一条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ds)) # 总共84条微调指令数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './Qwen/Qwen2-1___5B-Instruct'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False, trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 2048    # Llama分词器会将一个中文字切分为多个token，因此需要放开一些最大长度，保证数据的完整性\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(f\"<|im_start|>system\\n你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。<|im_end|>\\n<|im_start|>user\\n{example['instruction'] + example['input']}<|im_end|>\\n<|im_start|>assistant\\n\", add_special_tokens=False)  # add_special_tokens 不在开头加 special_tokens\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]  # 因为eos token咱们也是要关注的所以 补充为1\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]  \n",
    "    if len(input_ids) > MAX_LENGTH:  # 做一个截断\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_id = ds.map(process_func, remove_columns=ds.column_names)\n",
    "tokenized_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(tokenized_id[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(tokenized_id[1]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(list(filter(lambda x: x != -100, tokenized_id[1][\"labels\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\",torch_dtype=torch.bfloat16)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.enable_input_require_grads() # 开启梯度检查点时，要执行该方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False, # 训练模式\n",
    "    r=8, # Lora 秩\n",
    "    lora_alpha=32, # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.1# Dropout 比例\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_path = \"./output/Qwen2-1_5B-Instruct_novel_all\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=lora_path,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=100,\n",
    "    save_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_path = \"./output/Qwen2-1_5B-Instruct_novel_all\"\n",
    "trainer.save_model(lora_path + \"/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "model_path = './Qwen/Qwen2-1___5B-Instruct'\n",
    "lora_path = \"./output/Qwen2-1_5B-Instruct_novel_all/final\"\n",
    "\n",
    "max_new_tokens = 2048\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False, # 训练模式\n",
    "    r=8, # Lora 秩\n",
    "    lora_alpha=32, # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.1# Dropout 比例\n",
    ")\n",
    "\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\",torch_dtype=torch.bfloat16)\n",
    "\n",
    "# 加载lora权重\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path, config=config)\n",
    "\n",
    "## 傲慢与偏见 data[0]\n",
    "    # {\n",
    "    #     \"instruction\": \"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\",\n",
    "    #     \"input\": \"一个有钱的单身汉必定想要娶妻，这是社会普遍认同的事实。班纳特太太兴奋地告诉丈夫，尼日斐花园被一位名叫彬格莱的富绅租下，她希望他能成为女儿们的潜在配偶，而班纳特先生则以幽默的方式回应她的期望。\",\n",
    "    #     \"output\": \"凡是有钱的单身汉，总想娶位太太，这已经成了一条举世公认的真理。这样的单身汉，每逢新搬到一个地方，四邻八舍虽然完全不了解他的性情如何，见解如何，可是，既然这样的一条真理早已在人们心目中根深蒂固，因此人们总是把他看作自己某一个女儿理所应得的一笔财产。\\n有一天班纳特太太对她的丈夫说：“我的好老爷，尼日斐花园终于租出去了，你听说过没有？”班纳特先生回答道，他没有听说过。\\n“的确租出去了，”她说，“朗格太太刚刚上这儿来过，她把这件事的底细，一五一十地告诉了我。”班纳特先生没有理睬她。\\n“你难道不想知道是谁租去的吗？”太太不耐烦地嚷起来了。\\n“既是你要说给我听，我听听也无妨。”这句话足够鼓励她讲下去了。\\n“哦！亲爱的，你得知道，郎格太太说，租尼日斐花园的是个阔少爷，他是英格兰北部的人；听说他星期一那天，乘着一辆驷马大轿车来看房子，看得非常中意，当场就和莫理斯先生谈妥了；他要在‘米迦勒节’以前搬进来，打算下个周未先叫几个佣人来住。”“这个人叫什么名字？”“彬格莱。”“有太太的呢，还是单身汉？”“噢！是个单身汉，亲爱的，确确实实是个单身汉！一个有钱的单身汉；每年有四五千磅的收入。真是女儿们的福气！”“这怎么说？关女儿女儿们什么事？”“我的好老爷，”太太回答道，“你怎么这样叫人讨厌！告诉你吧，我正在盘算，他要是挑中我们一个女儿做老婆，可多好！”“他住到这儿来，就是为了这个打算吗？”“打算！胡扯，这是哪儿的话！不过，他倒作兴看中我们的某一个女儿呢。他一搬来，你就得去拜访拜访他。”“我不用去。你带着女儿们去就得啦，要不你干脆打发她们自己去，那或许倒更好些，因为你跟女儿们比起来，她们哪一个都不能胜过你的美貌，你去了，彬格莱先生倒可能挑中你呢？”“我的好老爷，你太捧我啦。从前也的确有人赞赏过我的美貌，现在我可有敢说有什么出众的地方了。一个女人家有了五个成年的女儿，就不该对自己的美貌再转什么念头。”“这样看来，一个女人家对自己的美貌也转不了多少念头喽。\"\n",
    "    # },\n",
    "\n",
    "\n",
    "prompt = \"一个有钱的单身汉必定想要娶妻，这是社会普遍认同的事实。班纳特太太兴奋地告诉丈夫，尼日斐花园被一位名叫彬格莱的富绅租下，她希望他能成为女儿们的潜在配偶，而班纳特先生则以幽默的方式回应她的期望。\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=max_new_tokens\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1.1现代励志故事，一个失业青年如何克服生活困境，终于实现自我突破，成为行业翘楚的心路历程\n",
    "1.2一个现代女性穿越到古代某朝代后发生的传奇故事\n",
    "1.3现代背景，一名神探警察遇到了一桩棘手的连环失踪案并将其侦破的故事\n",
    "1.4古代背景，皇家侍卫和公主历经层层考验，突破身份桎梏的爱情故事\n",
    "1.5现代玄幻背景，在一所驯服神兽的魔法学校中，围绕着三个学生小伙伴发生的奇幻冒险故事\n",
    "1.6古代侦探系列，一位才华横溢的年轻学士，在解决一连串神秘案件中揭露皇室阴谋的故事\n",
    "1.7二十一世纪初，一个小镇上发生的一系列神秘事件，让一群青少年开始探索超自然现象，并发现了小镇隐藏的古老秘密的故事\n",
    "1.8现代都市背景，一个名不见经传的漫画家，通过与自己创作的虚拟角色“交流”，解决一系列诡秘案件的故事\n",
    "1.9古代异界背景，一位天赋异禀的少年，在师傅的指导下学习古老的灵术，最终踏上寻找失落的神器，拯救家园的冒险旅程的故事\n",
    "1.10繁华都市背景，一个单亲妈妈如何在抚养孩子和维持生计之间找到平衡，同时保持对自己梦想的追求的故事\n",
    "1.11现代悬疑系列，一位心理学家利用自己的专业知识，帮助警方侦破一系列复杂的心理游戏案件\n",
    "1.12现代心理惊悚背景，一名精神科医生被卷入一连串的脑控实验阴谋，如何在精神与现实的边缘徘徊求生的故事\n",
    "1.13虚构古代背景，一位年轻的书生因缘巧合获得一本神秘典籍，开启了他成为一代宗师的修道之旅\n",
    "1.14古代神话背景，一位勇者如何经过重重试炼，最终获取神器，拯救世界于水深火热之中的传奇故事\n",
    "1.15虚拟现实背景，一群玩家在一款极度真实的VR游戏中探索未知世界并揭露游戏背后隐藏的秘密的故事\n",
    "1.16穿越时空背景，一群来自不同时代的人意外聚集在一个神秘的地方，他们如何互相协作，解开时空之谜的故事\n",
    "1.17科幻背景，一个机器人意识觉醒后，它如何在追求自我身份的同时，挑战人类社会关于存在和自由的根本问题\n",
    "1.1820世纪60年代的欧洲，一个侦探在解决一起跨国艺术品盗窃案中，逐渐揭露出一个关于失落宝藏的大阴谋\n",
    "1.19现代都市背景，一位因交通事故失去双腿的舞者，通过先进的义肢技术重新站起来，重新找回舞台与自我的故事\n",
    "1.20古代背景，一个普通医女奋斗成为朝廷高官，最终影响整个王朝政治格局变化的故事\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = [ \n",
    "\"现代励志故事，一个失业青年如何克服生活困境，终于实现自我突破，成为行业翘楚的心路历程。\",\n",
    " \"一个现代女性穿越到古代某朝代后发生的传奇故事。\", \n",
    " \"现代背景，一名神探警察遇到了一桩棘手的连环失踪案并将其侦破的故事。\", \n",
    " \"古代背景，皇家侍卫和公主历经层层考验，突破身份桎梏的爱情故事。\", \n",
    " \"现代玄幻背景，在一所驯服神兽的魔法学校中，围绕着三个学生小伙伴发生的奇幻冒险故事。\", \n",
    " \"古代侦探系列，一位才华横溢的年轻学士，在解决一连串神秘案件中揭露皇室阴谋的故事。\", \n",
    " \"二十一世纪初，一个小镇上发生的一系列神秘事件，让一群青少年开始探索超自然现象，并发现了小镇隐藏的古老秘密的故事。\", \n",
    " \"现代都市背景，一个名不见经传的漫画家，通过与自己创作的虚拟角色“交流”，解决一系列诡秘案件的故事。\", \n",
    " \"古代异界背景，一位天赋异禀的少年，在师傅的指导下学习古老的灵术，最终踏上寻找失落的神器，拯救家园的冒险旅程的故事。\", \n",
    " \"繁华都市背景，一个单亲妈妈如何在抚养孩子和维持生计之间找到平衡，同时保持对自己梦想的追求的故事。\", \n",
    " \"现代悬疑系列，一位心理学家利用自己的专业知识，帮助警方侦破一系列复杂的心理游戏案件。\", \n",
    " \"现代心理惊悚背景，一名精神科医生被卷入一连串的脑控实验阴谋，如何在精神与现实的边缘徘徊求生的故事。\", \n",
    " \"虚构古代背景，一位年轻的书生因缘巧合获得一本神秘典籍，开启了他成为一代宗师的修道之旅。\", \n",
    " \"古代神话背景，一位勇者如何经过重重试炼，最终获取神器，拯救世界于水深火热之中的传奇故事。\", \n",
    " \"虚拟现实背景，一群玩家在一款极度真实的VR游戏中探索未知世界并揭露游戏背后隐藏的秘密的故事。\", \n",
    " \"穿越时空背景，一群来自不同时代的人意外聚集在一个神秘的地方，他们如何互相协作，解开时空之谜的故事。\", \n",
    " \"科幻背景，一个机器人意识觉醒后，它如何在追求自我身份的同时，挑战人类社会关于存在和自由的根本问题。\",\n",
    "  \"20世纪60年代的欧洲，一个侦探在解决一起跨国艺术品盗窃案中，逐渐揭露出一个关于失落宝藏的大阴谋。\", \n",
    "  \"现代都市背景，一位因交通事故失去双腿的舞者，通过先进的义肢技术重新站起来，重新找回舞台与自我的故事。\", \n",
    "  \"古代背景，一个普通医女奋斗成为朝廷高官，最终影响整个王朝政治格局变化的故事。\" \n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 微调模型配置\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "model_path = './Qwen/Qwen2-1___5B-Instruct'\n",
    "lora_path = \"./output/Qwen2-1_5B-Instruct_novel_all/final\"\n",
    "\n",
    "max_new_tokens = 2048\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\",torch_dtype=torch.bfloat16)\n",
    "\n",
    "# 加载lora权重\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批处理函数\n",
    "def baseline_model(tasks,model):\n",
    "    res = []\n",
    "    for task in tqdm(tasks):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\"},\n",
    "            {\"role\": \"user\", \"content\": task}\n",
    "        ]\n",
    "        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda')\n",
    "        # 为了演示我们只生成三条, 正式提交时,请改为50\n",
    "        num_gen = 50\n",
    "        for n in range(num_gen):\n",
    "            generated_ids = model.generate(\n",
    "                model_inputs.input_ids,\n",
    "                max_new_tokens=max_new_tokens\n",
    "            )\n",
    "            generated_ids = [\n",
    "                output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "            ]\n",
    "\n",
    "            response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "            res.append({\n",
    "                \"instruction\":\"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\",\n",
    "                \"input\":task,\n",
    "                \"output\":response,\n",
    "            })\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动批处理存为json 这里生成第一个小说为例~\n",
    "res_novel = baseline_model(stories[:],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看结果~\n",
    "res_novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res_novel), len(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了保证可以提交我们针对每个小说题目生成了空数据  我们只填入前三条~\n",
    "\n",
    "import json\n",
    "with open(\"submit.json\", \"w\") as file:\n",
    "    for task_id, task in enumerate(stories):\n",
    "        print(task)\n",
    "        for t in range(50):\n",
    "            response = ''\n",
    "            data = {\n",
    "                \"instruction\":\"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\",\n",
    "                \"input\":task,\n",
    "                \"output\":response,\n",
    "            }\n",
    "            # if(task==stories[0] and t<3):\n",
    "            #     data =  res_novel[t]\n",
    "            data = res_novel[task_id*50+t%50]\n",
    "        # 将每个元素写入文件，并添加换行符\n",
    "            file.write(json.dumps(data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
